{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_final_print.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BndsnBxbAvit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaWkSN-Kgw6N",
        "colab_type": "code",
        "outputId": "cda26482-49f4-4c7d-f511-c4bfac57cfe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# 下載想要的語言版本 -q: 安靜模式\n",
        "!wget -q http://www.manythings.org/anki/cmn-eng.zip\n",
        "# 解壓縮zip -o: 覆蓋原本\n",
        "!unzip -o cmn-eng.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cmn-eng.zip\n",
            "  inflating: cmn.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK8cR-F6ipOh",
        "colab_type": "code",
        "outputId": "8756beb9-a441-4bef-85f8-c67f54cd3d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"cmn.txt\", \n",
        "                 sep=\"\\t\",\n",
        "                 header=None)\n",
        "df.columns = [\"English\", \"Chinese\", \"By\"]\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Chinese</th>\n",
              "      <th>By</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>嗨。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>你好。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run.</td>\n",
              "      <td>你用跑的。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>等等！</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>你好。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21200</th>\n",
              "      <td>Last year in the Philippines, earthquakes and ...</td>\n",
              "      <td>去年在菲律宾，地震和海啸造成了超过6000人的死亡。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21201</th>\n",
              "      <td>My mother speaks French better than my father ...</td>\n",
              "      <td>我母亲的法语比我父亲的英语要好，所以他们通常用法语交流。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21202</th>\n",
              "      <td>Tom didn't know how to translate the word \"com...</td>\n",
              "      <td>汤姆不知如何翻译“计算机”一词，因为同他谈话的人从未见过一台。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21203</th>\n",
              "      <td>Even now, I occasionally think I'd like to see...</td>\n",
              "      <td>即使是现在，我偶尔还是想见到你。不是今天的你，而是我记忆中曾经的你。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21204</th>\n",
              "      <td>If a person has not had a chance to acquire hi...</td>\n",
              "      <td>如果一個人在成人前沒有機會習得目標語言，他對該語言的認識達到母語者程度的機會是相當小的。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21205 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  ...                                                 By\n",
              "0                                                    Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "1                                                    Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "2                                                   Run.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "3                                                  Wait!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "4                                                 Hello!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "...                                                  ...  ...                                                ...\n",
              "21200  Last year in the Philippines, earthquakes and ...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "21201  My mother speaks French better than my father ...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "21202  Tom didn't know how to translate the word \"com...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "21203  Even now, I occasionally think I'd like to see...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "21204  If a person has not had a chance to acquire hi...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "\n",
              "[21205 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-NF-t4ckjO4",
        "colab_type": "code",
        "outputId": "cd581aa4-0698-4adf-f3f4-3e8b6dfa04f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# 使用opencc將簡中翻譯成繁中\n",
        "!pip install opencc-python-reimplemented"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencc-python-reimplemented\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/0c/c499c86a719c925a08586085a56f92f3235c03ee8b4db2e59c1e9aab3f55/opencc-python-reimplemented-0.1.5.tar.gz (482kB)\n",
            "\r\u001b[K     |▊                               | 10kB 25.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: opencc-python-reimplemented\n",
            "  Building wheel for opencc-python-reimplemented (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opencc-python-reimplemented: filename=opencc_python_reimplemented-0.1.5-py2.py3-none-any.whl size=485661 sha256=cd3bffedd24486582a31afe77ba1168be3d1f7db505fb6b8b3b5e713329b4dd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/a0/10/888b9ac7f10154caaa6a73270b1f085e0a7b241baa672bbe49\n",
            "Successfully built opencc-python-reimplemented\n",
            "Installing collected packages: opencc-python-reimplemented\n",
            "Successfully installed opencc-python-reimplemented-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHHsR2yvkIcK",
        "colab_type": "code",
        "outputId": "aa7fbe7c-748d-43b7-f6c0-12b0446beaf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "from opencc import OpenCC\n",
        "t = OpenCC(\"s2tw\")\n",
        "df[\"Chinese\"] = df[\"Chinese\"].apply(lambda s:t.convert(s))\n",
        "df = df.drop([\"By\"], axis=1)\n",
        "df.to_csv(\"en_zh.csv\")\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Chinese</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>嗨。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>你好。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run.</td>\n",
              "      <td>你用跑的。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>等等！</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>你好。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21200</th>\n",
              "      <td>Last year in the Philippines, earthquakes and ...</td>\n",
              "      <td>去年在菲律賓，地震和海嘯造成了超過6000人的死亡。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21201</th>\n",
              "      <td>My mother speaks French better than my father ...</td>\n",
              "      <td>我母親的法語比我父親的英語要好，所以他們通常用法語交流。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21202</th>\n",
              "      <td>Tom didn't know how to translate the word \"com...</td>\n",
              "      <td>湯姆不知如何翻譯“計算機”一詞，因為同他談話的人從未見過一臺。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21203</th>\n",
              "      <td>Even now, I occasionally think I'd like to see...</td>\n",
              "      <td>即使是現在，我偶爾還是想見到你。不是今天的你，而是我記憶中曾經的你。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21204</th>\n",
              "      <td>If a person has not had a chance to acquire hi...</td>\n",
              "      <td>如果一個人在成人前沒有機會習得目標語言，他對該語言的認識達到母語者程度的機會是相當小的。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21205 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English                                       Chinese\n",
              "0                                                    Hi.                                            嗨。\n",
              "1                                                    Hi.                                           你好。\n",
              "2                                                   Run.                                         你用跑的。\n",
              "3                                                  Wait!                                           等等！\n",
              "4                                                 Hello!                                           你好。\n",
              "...                                                  ...                                           ...\n",
              "21200  Last year in the Philippines, earthquakes and ...                    去年在菲律賓，地震和海嘯造成了超過6000人的死亡。\n",
              "21201  My mother speaks French better than my father ...                  我母親的法語比我父親的英語要好，所以他們通常用法語交流。\n",
              "21202  Tom didn't know how to translate the word \"com...               湯姆不知如何翻譯“計算機”一詞，因為同他談話的人從未見過一臺。\n",
              "21203  Even now, I occasionally think I'd like to see...            即使是現在，我偶爾還是想見到你。不是今天的你，而是我記憶中曾經的你。\n",
              "21204  If a person has not had a chance to acquire hi...  如果一個人在成人前沒有機會習得目標語言，他對該語言的認識達到母語者程度的機會是相當小的。\n",
              "\n",
              "[21205 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nm6lG2hcTeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 預處理Step1. 數出有多少種不同的詞彙\n",
        "inputs = []\n",
        "targets = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "for target_text, input_text in zip(df[\"Chinese\"], df[\"English\"]):\n",
        "    # 這裡比較特別, 在真正最後預測的時候你是喂start token給decoder\n",
        "    # 再等到decoder輸出end token結束\n",
        "    # 所以我們自定義 \\t 為 start token, \\n 為 decode token\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    # encoder 吃的不用加 \\t \\n\n",
        "    inputs.append(input_text)\n",
        "    # decoder 吃的加 \\t \\n\n",
        "    targets.append(target_text)\n",
        "    # 把不同種的詞紀錄, 由於我們使用set, 所以會自動把重複的去掉\n",
        "    for char in input_text:\n",
        "        input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        target_characters.add(char)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov7lR0SKd8ot",
        "colab_type": "code",
        "outputId": "2468b765-4743-4142-c5ef-1a49a129700e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "# 把我們的一些參數列出來一下\n",
        "# 順便先計算最長的輸入和輸出長度, 等等喂給模型\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters) + 1\n",
        "num_decoder_tokens = len(target_characters) + 1\n",
        "max_encoder_seq_length = max([len(txt) for txt in inputs])\n",
        "max_decoder_seq_length = max([len(txt) for txt in targets])\n",
        "\n",
        "print(\"資料集筆數:\", len(inputs))\n",
        "print(\"輸入的所有字彙:\", num_encoder_tokens)\n",
        "print(\"輸出的所有字彙:\", num_decoder_tokens)\n",
        "print(\"最長的輸入句子有多長:\", max_encoder_seq_length)\n",
        "print('最長的輸出句子有多長:', max_decoder_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "資料集筆數: 21205\n",
            "輸入的所有字彙: 76\n",
            "輸出的所有字彙: 2761\n",
            "最長的輸入句子有多長: 163\n",
            "最長的輸出句子有多長: 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imWaEeTUhZo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 給每一個字彙一個編號, 輸入輸出都要\n",
        "# 建立 文字 -> 數字 的查詢辭典 \n",
        "# 養成習慣留一個 <PAD> 字符, 我們習慣給0, 到時候不夠長度的句子我們就補0\n",
        "inputs_char_int = {char:i+1 for i, char in enumerate(input_characters)}\n",
        "inputs_char_int[\"<PAD>\"] = 0\n",
        "targets_char_int = {char:i+1 for i, char in enumerate(target_characters)}\n",
        "targets_char_int[\"<PAD>\"] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP9641j6h8Ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 建立 數字 -> 文字 的查詢辭典 \n",
        "inputs_int_char = {i:char for char, i in inputs_char_int.items()}\n",
        "targets_int_char = {i:char for char, i in targets_char_int.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKllqhMOl3KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 訓練參數\n",
        "# batch: 多少筆資料更新一次\n",
        "# embedding dimension: 先把每一種不同的東西降維\n",
        "# dim: LSTM/RNN的維度\n",
        "batch_size = 64 \n",
        "embedding_dim = 256\n",
        "dim = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL_feN2ripZW",
        "colab_type": "code",
        "outputId": "1fa61366-7ca4-4237-b336-88858ed480a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed\n",
        "\n",
        "input1 = Input(shape=(None,))\n",
        "x = Embedding(num_encoder_tokens, embedding_dim, mask_zero=True)(input1)\n",
        "x, state_h, state_c = LSTM(dim, return_state=True)(x)\n",
        "\n",
        "input2 = Input(shape=(None,))\n",
        "y = Embedding(num_decoder_tokens, embedding_dim, name=\"decoder_embedding\", mask_zero=True)(input2)\n",
        "y, _, _ = LSTM(dim, return_sequences=True, \n",
        "               return_state=True, \n",
        "               name=\"decoder_lstm\")(y, initial_state=[state_h, state_c])\n",
        "y = Dense(num_decoder_tokens, activation='softmax', name=\"decoder_dense\")(y)\n",
        "\n",
        "model = Model(inputs=[input1, input2], outputs=y)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 256)    19456       input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_embedding (Embedding)   (None, None, 256)    706816      input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, 256), (None, 525312      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 256),  525312      decoder_embedding[0][0]          \n",
            "                                                                 lstm_3[0][1]                     \n",
            "                                                                 lstm_3[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder_dense (Dense)           (None, None, 2761)   709577      decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,486,473\n",
            "Trainable params: 2,486,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgbZ_p4CCe-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T_2qlYxP03j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "en = []\n",
        "dein = []\n",
        "deout = []\n",
        "for sentence in inputs:\n",
        "    l = [inputs_char_int[c] for c in sentence]\n",
        "    en.append(l)\n",
        "en = pad_sequences(en, maxlen=max_encoder_seq_length, padding=\"post\")\n",
        "for sentence in targets:\n",
        "    l = [targets_char_int[c] for c in sentence[:-1]]\n",
        "    dein.append(l)\n",
        "    o = [targets_char_int[c] for c in sentence[1:]]\n",
        "    deout.append(o)\n",
        "    \n",
        "dein = pad_sequences(dein, maxlen=max_decoder_seq_length, padding=\"post\")\n",
        "deout = pad_sequences(deout, maxlen=max_decoder_seq_length, padding=\"post\")\n",
        "deout = deout.reshape(len(deout), -1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQRzFhLC1jcb",
        "colab_type": "code",
        "outputId": "efcfa89e-e5ab-408c-da41-201f8f5b0573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# 輸入資料長的樣子\n",
        "for seq in en[:10]:\n",
        "    print([inputs_int_char[s] for s in seq])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['H', 'i', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['H', 'i', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['R', 'u', 'n', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['W', 'a', 'i', 't', '!', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['H', 'e', 'l', 'l', 'o', '!', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['I', ' ', 't', 'r', 'y', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['I', ' ', 'w', 'o', 'n', '!', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['O', 'h', ' ', 'n', 'o', '!', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['C', 'h', 'e', 'e', 'r', 's', '!', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['G', 'o', 't', ' ', 'i', 't', '?', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXRhF-QJ0leA",
        "colab_type": "code",
        "outputId": "76f58ee0-b324-42ca-b853-ccdd4470a3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# 正確答案長的樣子\n",
        "for seq in deout[:10]:\n",
        "    print([targets_int_char[s[0]] for s in seq])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['嗨', '。', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['你', '好', '。', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['你', '用', '跑', '的', '。', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['等', '等', '！', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['你', '好', '。', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['讓', '我', '來', '。', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['我', '贏', '了', '。', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['不', '會', '吧', '。', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['乾', '杯', '!', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['你', '懂', '了', '嗎', '？', '\\n', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCJWrEZnEw_9",
        "colab_type": "code",
        "outputId": "643877b1-d6aa-4f43-c4e0-1726a544d067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 大約訓練50~100次\n",
        "model.fit([en, dein], deout,\n",
        "          batch_size=batch_size,\n",
        "          epochs=50,\n",
        "          validation_split=0.1,\n",
        "          verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 19084 samples, validate on 2121 samples\n",
            "Epoch 1/50\n",
            " - 159s - loss: 0.1071 - val_loss: 6.7358\n",
            "Epoch 2/50\n",
            " - 159s - loss: 0.3344 - val_loss: 6.6526\n",
            "Epoch 3/50\n",
            " - 158s - loss: 0.1115 - val_loss: 6.6531\n",
            "Epoch 4/50\n",
            " - 158s - loss: 0.0477 - val_loss: 6.6519\n",
            "Epoch 5/50\n",
            " - 156s - loss: 0.0304 - val_loss: 6.6803\n",
            "Epoch 6/50\n",
            " - 158s - loss: 0.0254 - val_loss: 6.7038\n",
            "Epoch 7/50\n",
            " - 157s - loss: 0.0236 - val_loss: 6.7032\n",
            "Epoch 8/50\n",
            " - 156s - loss: 0.0231 - val_loss: 6.7218\n",
            "Epoch 9/50\n",
            " - 156s - loss: 0.0231 - val_loss: 6.7436\n",
            "Epoch 10/50\n",
            " - 158s - loss: 0.0237 - val_loss: 6.7407\n",
            "Epoch 11/50\n",
            " - 156s - loss: 0.0251 - val_loss: 6.7696\n",
            "Epoch 12/50\n",
            " - 156s - loss: 0.0766 - val_loss: 6.8499\n",
            "Epoch 13/50\n",
            " - 157s - loss: 0.3360 - val_loss: 6.7466\n",
            "Epoch 14/50\n",
            " - 157s - loss: 0.1113 - val_loss: 6.7286\n",
            "Epoch 15/50\n",
            " - 157s - loss: 0.0466 - val_loss: 6.7277\n",
            "Epoch 16/50\n",
            " - 157s - loss: 0.0287 - val_loss: 6.7469\n",
            "Epoch 17/50\n",
            " - 157s - loss: 0.0234 - val_loss: 6.7655\n",
            "Epoch 18/50\n",
            " - 158s - loss: 0.0216 - val_loss: 6.7678\n",
            "Epoch 19/50\n",
            " - 157s - loss: 0.0213 - val_loss: 6.7850\n",
            "Epoch 20/50\n",
            " - 158s - loss: 0.0212 - val_loss: 6.8017\n",
            "Epoch 21/50\n",
            " - 157s - loss: 0.0224 - val_loss: 6.8252\n",
            "Epoch 22/50\n",
            " - 158s - loss: 0.0229 - val_loss: 6.8299\n",
            "Epoch 23/50\n",
            " - 156s - loss: 0.0252 - val_loss: 6.8266\n",
            "Epoch 24/50\n",
            " - 156s - loss: 0.2026 - val_loss: 6.8324\n",
            "Epoch 25/50\n",
            " - 156s - loss: 0.2339 - val_loss: 6.8001\n",
            "Epoch 26/50\n",
            " - 158s - loss: 0.0796 - val_loss: 6.7824\n",
            "Epoch 27/50\n",
            " - 156s - loss: 0.0364 - val_loss: 6.7984\n",
            "Epoch 28/50\n",
            " - 156s - loss: 0.0251 - val_loss: 6.8161\n",
            "Epoch 29/50\n",
            " - 155s - loss: 0.0214 - val_loss: 6.8238\n",
            "Epoch 30/50\n",
            " - 155s - loss: 0.0206 - val_loss: 6.8410\n",
            "Epoch 31/50\n",
            " - 156s - loss: 0.0204 - val_loss: 6.8453\n",
            "Epoch 32/50\n",
            " - 157s - loss: 0.0208 - val_loss: 6.8514\n",
            "Epoch 33/50\n",
            " - 156s - loss: 0.0211 - val_loss: 6.8842\n",
            "Epoch 34/50\n",
            " - 157s - loss: 0.0217 - val_loss: 6.8982\n",
            "Epoch 35/50\n",
            " - 156s - loss: 0.0237 - val_loss: 6.9178\n",
            "Epoch 36/50\n",
            " - 157s - loss: 0.1851 - val_loss: 6.9127\n",
            "Epoch 37/50\n",
            " - 157s - loss: 0.2407 - val_loss: 6.8732\n",
            "Epoch 38/50\n",
            " - 159s - loss: 0.0786 - val_loss: 6.8704\n",
            "Epoch 39/50\n",
            " - 157s - loss: 0.0371 - val_loss: 6.8792\n",
            "Epoch 40/50\n",
            " - 158s - loss: 0.0239 - val_loss: 6.8753\n",
            "Epoch 41/50\n",
            " - 157s - loss: 0.0206 - val_loss: 6.8899\n",
            "Epoch 42/50\n",
            " - 155s - loss: 0.0197 - val_loss: 6.8908\n",
            "Epoch 43/50\n",
            " - 154s - loss: 0.0190 - val_loss: 6.9021\n",
            "Epoch 44/50\n",
            " - 154s - loss: 0.0194 - val_loss: 6.9136\n",
            "Epoch 45/50\n",
            " - 153s - loss: 0.0197 - val_loss: 6.9233\n",
            "Epoch 46/50\n",
            " - 153s - loss: 0.0211 - val_loss: 6.9234\n",
            "Epoch 47/50\n",
            " - 154s - loss: 0.0230 - val_loss: 6.9377\n",
            "Epoch 48/50\n",
            " - 154s - loss: 0.2283 - val_loss: 6.9539\n",
            "Epoch 49/50\n",
            " - 155s - loss: 0.1752 - val_loss: 6.9228\n",
            "Epoch 50/50\n",
            " - 155s - loss: 0.0598 - val_loss: 6.9267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1f4ee2fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5gwFKXpb1fx",
        "colab_type": "code",
        "outputId": "99efe933-6c01-4343-913e-1bc06929c29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 測試一下原本的他有沒有學會\n",
        "import numpy as np\n",
        "infer_encoder = Model(inputs=input1, outputs=[state_h, state_c])\n",
        "\n",
        "de_h = Input(shape=(dim,))\n",
        "de_c = Input(shape=(dim,))\n",
        "de = model.get_layer(\"decoder_embedding\")(input2)\n",
        "dex, next_h, next_c = model.get_layer(\"decoder_lstm\")(de, initial_state=[de_h, de_c])\n",
        "dex = model.get_layer(\"decoder_dense\")(dex)\n",
        "infer_decoder = Model(inputs=[input2, de_h, de_c],\n",
        "                      outputs=[dex, next_h, next_c])\n",
        "\n",
        "test = df.head(20)\n",
        "for e, z in zip(test[\"English\"], test[\"Chinese\"]):\n",
        "    print(\"Encode:\", e)\n",
        "    test_input1 = [inputs_char_int[c] for c in e]\n",
        "    test_input1 = np.array([test_input1])\n",
        "    h, c = infer_encoder.predict(test_input1)\n",
        "\n",
        "    result = \"\"\n",
        "    i = targets_char_int[\"\\t\"]\n",
        "    while True:\n",
        "        o, nexth, nextc = infer_decoder.predict([np.array([i]), h, c])\n",
        "        index = o.argmax()\n",
        "        result = result + targets_int_char[index]\n",
        "        i, h, c = index, nexth, nextc\n",
        "        if len(result) >= 100 or index == targets_char_int[\"\\n\"]:\n",
        "            print(\"Decode:\", result)\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encode: Hi.\n",
            "Decode: 你好。\n",
            "\n",
            "Encode: Hi.\n",
            "Decode: 你好。\n",
            "\n",
            "Encode: Run.\n",
            "Decode: 你用跑的。\n",
            "\n",
            "Encode: Wait!\n",
            "Decode: 等等！\n",
            "\n",
            "Encode: Hello!\n",
            "Decode: 你好。\n",
            "\n",
            "Encode: I try.\n",
            "Decode: 讓我來。\n",
            "\n",
            "Encode: I won!\n",
            "Decode: 我贏了。\n",
            "\n",
            "Encode: Oh no!\n",
            "Decode: 不會吧。\n",
            "\n",
            "Encode: Cheers!\n",
            "Decode: 乾杯!\n",
            "\n",
            "Encode: Got it?\n",
            "Decode: 你懂了嗎？\n",
            "\n",
            "Encode: He ran.\n",
            "Decode: 他跑了。\n",
            "\n",
            "Encode: Hop in.\n",
            "Decode: 跳進來。\n",
            "\n",
            "Encode: I lost.\n",
            "Decode: 我迷失了。\n",
            "\n",
            "Encode: I quit.\n",
            "Decode: 我退出。\n",
            "\n",
            "Encode: I'm OK.\n",
            "Decode: 我沒事。\n",
            "\n",
            "Encode: Listen.\n",
            "Decode: 聽著。\n",
            "\n",
            "Encode: No way!\n",
            "Decode: 沒門！\n",
            "\n",
            "Encode: No way!\n",
            "Decode: 沒門！\n",
            "\n",
            "Encode: Really?\n",
            "Decode: 你確定？\n",
            "\n",
            "Encode: Try it.\n",
            "Decode: 試試吧。\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ryo6ETo7vWE",
        "colab_type": "code",
        "outputId": "33b1f4c0-3c02-423a-d071-73bfdf1f60c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# 讓他試一下從沒看過的句子\n",
        "finaltest = [\"This is room 666\", \n",
        "             \"This is my money\",\n",
        "             \"I love your pencil\", \n",
        "             \"This is my pencil\", \n",
        "             \"I love Tom\",\n",
        "             \"Tom love me\"]\n",
        "for e in finaltest:\n",
        "    print(\"Encode:\", e)\n",
        "    test_input1 = [inputs_char_int[c] for c in e]\n",
        "    test_input1 = pad_sequences(np.array([test_input1]), maxlen=max_encoder_seq_length, padding=\"post\")\n",
        "    h, c = infer_encoder.predict(test_input1)\n",
        "\n",
        "    result = \"\"\n",
        "    i = targets_char_int[\"\\t\"]\n",
        "    while True:\n",
        "        o, nexth, nextc = infer_decoder.predict([np.array([i]), h, c])\n",
        "        index = o.argmax()\n",
        "        result = result + targets_int_char[index]\n",
        "        i, h, c = index, nexth, nextc\n",
        "        if len(result) >= 100 or index == targets_char_int[\"\\n\"]:\n",
        "            print(\"Decode:\", result)\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encode: This is room 666\n",
            "Decode: 這本書是個大的。\n",
            "\n",
            "Encode: This is my money\n",
            "Decode: 這是我的鑰匙。\n",
            "\n",
            "Encode: I love your pencil\n",
            "Decode: 我愛你的鋼筆。\n",
            "\n",
            "Encode: This is my pencil\n",
            "Decode: 這是我的鋼筆。\n",
            "\n",
            "Encode: I love Tom\n",
            "Decode: 我愛湯姆。\n",
            "\n",
            "Encode: Tom love me\n",
            "Decode: 湯姆愛我的他擁有的。\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
